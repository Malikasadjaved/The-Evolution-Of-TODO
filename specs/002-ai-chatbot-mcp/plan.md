# Implementation Plan: AI Chatbot with MCP Architecture

**Branch**: `002-ai-chatbot-mcp` | **Date**: 2025-12-25 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `specs/002-ai-chatbot-mcp/spec.md`

**Note**: This plan was generated by the `/sp.plan` command following the Phase 3 constitution (v1.1.0) and SpecifyPlus workflow.

## Summary

**Primary Requirement**: Build a conversational AI interface for todo management using stateless architecture with MCP (Model Context Protocol) tools, integrated into the existing To-do-app monorepo.

**Technical Approach**:
- **Four-Layer Architecture**: ChatKit UI → FastAPI Chat Endpoint → OpenAI Agent → MCP Server → Neon PostgreSQL
- **Radical Statelessness**: Zero server-side memory - database is single source of truth for all conversation state
- **MCP as Universal Interface**: All AI-to-application interactions flow through 5 atomic MCP tools only
- **Phase 2 Integration**: Share Task/User models, Better Auth JWT tokens, and Neon PostgreSQL database with existing web app
- **Cloud-Native Ready**: Health checks, graceful shutdown, 12-factor app compliance for Phase 4 Kubernetes deployment

**Success Criteria**: Users can manage todos through natural language conversation, tasks sync bidirectionally with Phase 2 web UI in <1 second, server can restart mid-conversation without data loss, ≥85% test coverage.

---

## Technical Context

**Language/Version**: Python 3.11+

**Primary Dependencies**:
- **Backend**: FastAPI 0.104+, SQLModel 0.0.14+, Pydantic 2.0+, Uvicorn 0.24+
- **AI/MCP**: OpenAI Agents SDK (latest), Official MCP SDK (Python), OpenAI Python SDK 1.0+
- **Database**: Neon Serverless PostgreSQL (shared with Phase 2), Alembic 1.12+ (migrations)
- **Auth**: Better Auth (shared with Phase 2), python-jose[cryptography] 3.3+ (JWT validation)
- **Frontend**: OpenAI ChatKit (latest), Next.js 16+ (if custom UI needed)
- **Testing**: pytest 7.4+, pytest-asyncio 0.21+, httpx 0.25+ (async test client)

**Storage**:
- **Existing Tables** (from Phase 2): `tasks` (id, user_id, title, description, priority, tags, due_date, status, created_at, updated_at), `users` (id, email, hashed_password, created_at)
- **New Tables** (Phase 3): `conversations` (id, user_id, created_at, updated_at), `messages` (id, conversation_id, user_id, role, content, created_at)
- **Database**: Neon PostgreSQL (serverless, shared with Phase 2)

**Testing**: pytest with 50+ unit tests (MCP tools, models), 15+ integration tests (API + Agent + MCP), 5+ E2E tests (complete conversation flows)

**Target Platform**: Linux server (development), Docker containers (staging/production), Kubernetes-ready (Phase 4)

**Project Type**: Web application (monorepo) - backend API + frontend chat UI

**Performance Goals**:
- Chat endpoint response time: < 5 seconds (P95)
- MCP tool execution: < 2 seconds per tool
- Database query latency: < 100ms
- Conversation history load: < 500ms for 50 messages
- Support 100 concurrent users

**Constraints**:
- **Statelessness**: ZERO server memory between requests - all state in database
- **MCP Boundary**: Agent NEVER touches database directly - MCP tools only
- **Single Endpoint**: POST /api/chat/{user_id} is the ONLY chat endpoint
- **Token Budget**: MAX_CONTEXT_TOKENS = 8,000 (conversation history limit)
- **Security**: All queries MUST filter by JWT token user_id (NEVER by URL user_id)

**Scale/Scope**:
- MVP: 100 concurrent users, 50 messages/conversation average, 10,000 total tasks
- Growth: Horizontal scaling ready (stateless architecture)

---

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

Based on `.specify/memory/phase-3-constitution.md` (v1.1.0), the following gates must pass:

### ✅ Gate 1: Agentic Development Supremacy (Principle I)
- [x] All code will be generated by Claude Code (NO manual coding)
- [x] Workflow follows: Spec → Plan → Tasks → Implementation
- [x] Prompt History Records (PHRs) will document every iteration

**Justification**: Plan created via `/sp.plan` command. Implementation will use Claude Code exclusively.

### ✅ Gate 2: Radical Statelessness (Principle II)
- [x] FastAPI holds ZERO conversation state in RAM
- [x] Database is single source of truth for all state
- [x] Conversation history loaded from DB on every request
- [x] Server can restart mid-conversation without data loss

**Design Evidence**:
- POST /api/chat/{user_id} loads conversation from DB
- No `conversation_cache = {}` or `@lru_cache` on conversation data
- All state persisted to `conversations` and `messages` tables

### ✅ Gate 3: MCP as Universal Interface (Principle III)
- [x] Agent interacts ONLY via 5 MCP tools (add_task, list_tasks, complete_task, delete_task, update_task)
- [x] Agent NEVER accesses database directly
- [x] Agent NEVER calls FastAPI endpoints
- [x] MCP Server is sole interface between agent and database

**Architecture Law Compliance**:
```
Agent → MCP Tool → Database Operation → Response → Agent
```

### ✅ Gate 4: Four-Layer Separation (Section II)
- [x] Layer 1: ChatKit UI (presentation)
- [x] Layer 2: FastAPI Endpoint (orchestration)
- [x] Layer 3: OpenAI Agent (intelligence)
- [x] Layer 4: MCP Server (tool execution)
- [x] Layer 5: PostgreSQL (persistence)
- [x] Layers only call Layer N+1 (no skipping)

### ✅ Gate 5: Cloud-Native Requirements (Section XIV - NEW in v1.1.0)
- [x] Health checks: /health (liveness), /ready (readiness)
- [x] Graceful shutdown: SIGTERM/SIGINT handlers
- [x] 12-factor app: Config via environment variables
- [x] Port binding: 0.0.0.0 (not 127.0.0.1)
- [x] Structured JSON logging to stdout

### ✅ Gate 6: Conversation History Management (Section XV - NEW in v1.1.0)
- [x] Token budget: MAX_CONTEXT_TOKENS = 8,000
- [x] Message limit: MAX_MESSAGES = 50
- [x] Truncation: Keep last 10 messages, summarize older
- [x] Character estimate: ~32,000 chars (8,000 tokens × 4 chars/token)

### ✅ Gate 7: Resilience (Section XVI - NEW in v1.1.0)
- [x] Circuit breaker for OpenAI API calls
- [x] Timeouts: 30s chat endpoint, 10s MCP tools
- [x] Fallback messages when services unavailable

**ALL GATES PASSED** ✅ - Proceed to Phase 0 research.

---

## Project Structure

### Documentation (this feature)

```text
specs/002-ai-chatbot-mcp/
├── plan.md              # This file (/sp.plan command output)
├── research.md          # Phase 0 output - OpenAI Agents SDK, MCP SDK research
├── data-model.md        # Phase 1 output - Conversation/Message SQLModel schemas
├── quickstart.md        # Phase 1 output - Local setup guide
├── contracts/           # Phase 1 output - API contracts
│   ├── chat-endpoint.md       # POST /api/chat/{user_id} contract
│   └── mcp-tools.md           # 5 MCP tool schemas
└── tasks.md             # Phase 2 output (/sp.tasks command - NOT created by /sp.plan)
```

### Source Code (monorepo structure)

```text
To-do-app/  (Monorepo Root)
├── backend/
│   ├── src/                     # Phase 2: Existing FastAPI REST API
│   │   ├── models/              # SHARED: Task, User models (Phase 2)
│   │   │   ├── task.py          # Task model (EXISTS - from Phase 2)
│   │   │   ├── user.py          # User model (EXISTS - from Phase 2)
│   │   │   ├── conversation.py  # NEW: Conversation model (Phase 3)
│   │   │   └── message.py       # NEW: Message model (Phase 3)
│   │   ├── api/
│   │   │   ├── auth.py          # EXISTS: JWT middleware (Phase 2)
│   │   │   ├── main.py          # EXISTS: FastAPI app (Phase 2)
│   │   │   └── chat.py          # NEW: Chat endpoint (Phase 3)
│   │   └── database.py          # EXISTS: Database connection (Phase 2)
│   │
│   ├── mcp/                     # NEW: Phase 3 MCP Server
│   │   ├── server.py            # MCP server initialization
│   │   ├── tools/               # 5 MCP tools (atomic, stateless)
│   │   │   ├── __init__.py
│   │   │   ├── add_task.py      # Tool 1: add_task
│   │   │   ├── list_tasks.py    # Tool 2: list_tasks
│   │   │   ├── complete_task.py # Tool 3: complete_task
│   │   │   ├── delete_task.py   # Tool 4: delete_task
│   │   │   └── update_task.py   # Tool 5: update_task
│   │   ├── schemas.py           # Pydantic input/output schemas
│   │   └── utils/
│   │       ├── conversation_manager.py  # History truncation logic
│   │       ├── circuit_breaker.py       # OpenAI API resilience
│   │       └── logger.py                # Structured JSON logging
│   │
│   └── tests/                   # NEW: Tests for Phase 3
│       ├── unit/
│       │   ├── test_mcp_tools.py      # 50+ tests for MCP tools
│       │   ├── test_models.py         # Conversation/Message models
│       │   └── test_conversation_manager.py  # History truncation
│       ├── integration/
│       │   ├── test_chat_endpoint.py  # API + Agent + MCP + DB
│       │   └── test_agent_orchestration.py
│       └── e2e/
│           └── test_conversation_flows.py  # Complete flows
│
├── frontend-web/                # Phase 2: Existing Next.js Web UI
│
├── frontend-chatbot/            # NEW: Phase 3 OpenAI ChatKit UI
│   ├── src/
│   │   ├── components/
│   │   │   └── ChatInterface.tsx    # ChatKit integration
│   │   ├── lib/
│   │   │   └── api.ts               # HTTP client for /api/chat
│   │   └── pages/
│   │       └── index.tsx            # Main chat page
│   ├── package.json
│   └── .env.local.example
│
├── .specify/
│   └── memory/
│       └── phase-3-constitution.md  # Phase 3 principles (v1.1.0)
│
└── docker-compose.yml           # UPDATED: Add chatbot services
```

**Structure Decision**: We're using Option 2 (Web application) from the template because this is a monorepo with existing `backend/` and `frontend-web/` directories from Phase 2. We add `backend/mcp/` for MCP server code and `frontend-chatbot/` for the new ChatKit UI. Shared models go in `backend/src/models/` to enable bidirectional access from both FastAPI REST API (Phase 2) and MCP Server (Phase 3).

---

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| N/A | No violations | All gates passed |

**Justification**: The design adheres to all constitutional requirements:
- Statelessness enforced (database-backed, no in-memory state)
- MCP boundary respected (agent → tools → DB, no shortcuts)
- Single endpoint pattern (POST /api/chat only)
- Agentic development workflow (this plan via Claude Code)
- Cloud-native ready (health checks, graceful shutdown, 12-factor)

---

## Phase 0: Research & Discovery

### Research Topics

#### 1. OpenAI Agents SDK (Critical)

**Questions**:
- How does OpenAI Agents SDK handle tool calling?
- What's the API for registering MCP tools with the agent?
- How do we pass conversation history to the agent?
- What's the expected response format?

**Research Tasks**:
- Read OpenAI Agents SDK documentation
- Find code examples for tool registration
- Understand conversation context management
- Identify error handling patterns

**Output**: Document in `research.md` with API examples

#### 2. Official MCP SDK (Python) (Critical)

**Questions**:
- What's the MCP protocol specification?
- How do we implement an MCP server in Python?
- How do we define tool schemas (input/output)?
- How does the agent invoke MCP tools?

**Research Tasks**:
- Review MCP protocol specification
- Find Python MCP SDK examples
- Understand tool registration and invocation flow
- Document error handling patterns

**Output**: Document in `research.md` with tool definition examples

#### 3. Token Counting & Context Management (Important)

**Questions**:
- How do we count tokens for conversation history?
- What's the exact token limit for GPT-4?
- How do we implement sliding window truncation?
- What's the optimal summary strategy?

**Research Tasks**:
- Use `tiktoken` library for accurate token counting
- Identify context window size for GPT-4 Turbo
- Test truncation strategies (last N messages vs. summarization)
- Benchmark character-to-token ratio (validate 4:1 assumption)

**Output**: Document in `research.md` with code examples

#### 4. OpenAI ChatKit Frontend (Medium Priority)

**Questions**:
- Is OpenAI ChatKit available as a library?
- If not, what's the recommended chat UI alternative?
- How do we integrate with our POST /api/chat endpoint?
- What's the authentication flow?

**Research Tasks**:
- Search for OpenAI ChatKit documentation
- Evaluate alternatives (Vercel AI Chat UI, custom React components)
- Document API integration requirements
- Identify deployment options

**Output**: Document in `research.md` with frontend architecture decision

#### 5. Phase 2 Integration Points (Critical)

**Questions**:
- What's the exact JWT payload structure from Better Auth?
- How do we validate JWT tokens in FastAPI?
- What's the current Task model schema?
- Are there any database indexes we need to be aware of?

**Research Tasks**:
- Read `backend/src/api/auth.py` (existing JWT middleware)
- Read `backend/src/models/task.py` (existing Task model)
- Check `backend/src/database.py` for connection patterns
- Document authentication flow

**Output**: Document in `research.md` with code references

**Success Criteria for Phase 0**: All NEEDS CLARIFICATION markers resolved, research.md complete with API examples and architecture decisions.

---

## Phase 1: Design & Contracts

### Data Model Design

#### NEW: Conversation Model

**File**: `backend/src/models/conversation.py`

```python
from sqlmodel import SQLModel, Field, Relationship
from datetime import datetime
from typing import Optional, List

class Conversation(SQLModel, table=True):
    """
    Represents a chat session between user and AI assistant.

    Design Rationale:
    - user_id denormalized for fast security checks (avoid JOIN)
    - created_at for session tracking
    - updated_at for identifying active conversations
    """
    __tablename__ = "conversations"

    id: Optional[int] = Field(default=None, primary_key=True)
    user_id: str = Field(index=True, nullable=False)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

    # Relationships
    messages: List["Message"] = Relationship(
        back_populates="conversation",
        sa_relationship_kwargs={"cascade": "all, delete-orphan"}
    )
```

**Indexes**:
- PRIMARY KEY: `id`
- INDEX: `user_id` (for filtering conversations by user)

**Migration Strategy**: Use SQLModel `create_all()` for development. For production, generate Alembic migration.

---

#### NEW: Message Model

**File**: `backend/src/models/message.py`

```python
from sqlmodel import SQLModel, Field, Relationship
from datetime import datetime
from typing import Optional, Literal

class Message(SQLModel, table=True):
    """
    Represents a single message in a conversation.

    Design Rationale:
    - user_id denormalized for security (fast auth checks without JOIN)
    - role enforced as "user" | "assistant" via Literal type
    - content stores full message text (no length limit for assistant responses)
    - created_at for ordering (conversation flow)
    """
    __tablename__ = "messages"

    id: Optional[int] = Field(default=None, primary_key=True)
    conversation_id: int = Field(foreign_key="conversations.id", index=True)
    user_id: str = Field(index=True, nullable=False)  # Denormalized for security
    role: Literal["user", "assistant"] = Field(nullable=False)
    content: str = Field(nullable=False)  # TEXT column (unlimited length)
    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)

    # Relationships
    conversation: Optional["Conversation"] = Relationship(back_populates="messages")
```

**Indexes**:
- PRIMARY KEY: `id`
- INDEX: `conversation_id` (for loading conversation history)
- INDEX: `user_id` (for security filtering)
- INDEX: `created_at` (for ordering by time)
- COMPOSITE INDEX: `(user_id, conversation_id)` (for user-specific history queries)

**Constraints**:
- `role` MUST be "user" or "assistant" (enforced by Pydantic)
- `content` cannot be empty
- CASCADE DELETE when conversation deleted

---

### API Contracts

#### Contract 1: POST /api/chat/{user_id}

**File**: `specs/002-ai-chatbot-mcp/contracts/chat-endpoint.md`

**Endpoint**: `POST /api/chat/{user_id}`

**Authentication**: JWT token required (Authorization: Bearer <token>)

**Request Schema**:
```json
{
  "conversation_id": 123,  // Optional: omit to start new conversation
  "message": "Add a task to buy groceries tomorrow"
}
```

**Request Validation**:
- `message`: Required, 1-5000 characters
- `conversation_id`: Optional integer, must belong to user_id if provided

**Response Schema** (Success):
```json
{
  "conversation_id": 123,
  "message_id": 456,
  "response": "I've added 'Buy groceries' with due date tomorrow to your task list!",
  "tool_calls": [
    {
      "tool": "add_task",
      "parameters": {
        "user_id": "user123",
        "title": "Buy groceries",
        "due_date": "2025-12-26"
      },
      "result": {
        "task_id": 42,
        "status": "created",
        "title": "Buy groceries"
      }
    }
  ]
}
```

**Error Responses**:
- `401 Unauthorized`: Missing or invalid JWT token
- `403 Forbidden`: Token user_id doesn't match URL user_id
- `404 Not Found`: conversation_id not found or doesn't belong to user
- `422 Unprocessable Entity`: Invalid message format
- `503 Service Unavailable`: OpenAI API down (circuit breaker open)

**Behavior**:
1. Validate JWT token, extract user_id
2. Verify token user_id == URL user_id (403 if mismatch)
3. If conversation_id provided, load conversation (404 if not found)
4. If conversation_id missing, create new conversation
5. Append user message to messages table
6. Load last 50 messages from conversation (ordered by created_at ASC)
7. Truncate history if > 8,000 tokens (keep last 10 messages + summarize older)
8. Invoke OpenAI Agent with conversation history
9. Agent determines intent and calls MCP tools as needed
10. Store agent response to messages table
11. Return response + tool_call metadata

---

#### Contract 2: MCP Tools

**File**: `specs/002-ai-chatbot-mcp/contracts/mcp-tools.md`

**Tool 1: add_task**

**Input Schema**:
```python
class AddTaskInput(BaseModel):
    user_id: str = Field(..., description="User ID from JWT token")
    title: str = Field(..., min_length=1, max_length=500)
    description: str = Field(default="")
    priority: Literal["HIGH", "MEDIUM", "LOW"] = Field(default="MEDIUM")
    tags: List[str] = Field(default_factory=list)
    due_date: Optional[str] = Field(default=None, description="ISO 8601 datetime")
```

**Output Schema**:
```python
class AddTaskOutput(BaseModel):
    task_id: int
    status: Literal["created"]
    title: str
    due_date: Optional[str] = None
```

**Error Cases**:
- Empty title: `{"error": "Title cannot be empty"}`
- Database error: `{"error": "Failed to create task", "details": "..."}`

**Pseudocode**:
```python
async def add_task(input: AddTaskInput, db: Session) -> AddTaskOutput:
    task = Task(
        user_id=input.user_id,
        title=input.title,
        description=input.description,
        priority=input.priority,
        tags=input.tags,
        due_date=parse_iso8601(input.due_date) if input.due_date else None,
        status="INCOMPLETE",
        created_at=datetime.utcnow(),
        updated_at=datetime.utcnow()
    )
    db.add(task)
    db.commit()
    db.refresh(task)
    return AddTaskOutput(
        task_id=task.id,
        status="created",
        title=task.title,
        due_date=task.due_date.isoformat() if task.due_date else None
    )
```

---

**Tool 2: list_tasks**

**Input Schema**:
```python
class ListTasksInput(BaseModel):
    user_id: str
    status_filter: Literal["all", "pending", "completed"] = "all"
    priority_filter: Optional[Literal["HIGH", "MEDIUM", "LOW"]] = None
    tag_filter: Optional[str] = None
```

**Output Schema**:
```python
class ListTasksOutput(BaseModel):
    tasks: List[TaskSummary]
    count: int
    filter: str

class TaskSummary(BaseModel):
    id: int
    title: str
    priority: str
    status: str
    due_date: Optional[str] = None
    tags: List[str]
    created_at: str
```

**Pseudocode**:
```python
async def list_tasks(input: ListTasksInput, db: Session) -> ListTasksOutput:
    query = db.query(Task).filter(Task.user_id == input.user_id)

    if input.status_filter == "pending":
        query = query.filter(Task.status == "INCOMPLETE")
    elif input.status_filter == "completed":
        query = query.filter(Task.status == "COMPLETE")

    if input.priority_filter:
        query = query.filter(Task.priority == input.priority_filter)

    if input.tag_filter:
        query = query.filter(Task.tags.contains([input.tag_filter]))

    tasks = query.order_by(Task.created_at.desc()).all()

    return ListTasksOutput(
        tasks=[TaskSummary.from_orm(task) for task in tasks],
        count=len(tasks),
        filter=input.status_filter
    )
```

---

**Tool 3: complete_task**

**Input Schema**:
```python
class CompleteTaskInput(BaseModel):
    user_id: str
    task_id: int
```

**Output Schema**:
```python
class CompleteTaskOutput(BaseModel):
    task_id: int
    status: Literal["completed"]
    title: str
```

**Error Cases**:
- Task not found: `{"error": "Task not found", "task_id": <id>}`

**Pseudocode**:
```python
async def complete_task(input: CompleteTaskInput, db: Session) -> CompleteTaskOutput:
    task = db.query(Task).filter(
        Task.id == input.task_id,
        Task.user_id == input.user_id  # Security: user isolation
    ).first()

    if not task:
        raise TaskNotFoundError(input.task_id)

    task.status = "COMPLETE"
    task.updated_at = datetime.utcnow()
    db.commit()

    return CompleteTaskOutput(
        task_id=task.id,
        status="completed",
        title=task.title
    )
```

---

**Tool 4: delete_task**

**Input Schema**:
```python
class DeleteTaskInput(BaseModel):
    user_id: str
    task_id: int
```

**Output Schema**:
```python
class DeleteTaskOutput(BaseModel):
    task_id: int
    status: Literal["deleted"]
    title: str  # Title before deletion for confirmation
```

**Pseudocode**:
```python
async def delete_task(input: DeleteTaskInput, db: Session) -> DeleteTaskOutput:
    task = db.query(Task).filter(
        Task.id == input.task_id,
        Task.user_id == input.user_id
    ).first()

    if not task:
        raise TaskNotFoundError(input.task_id)

    title = task.title  # Save for response
    db.delete(task)
    db.commit()

    return DeleteTaskOutput(
        task_id=input.task_id,
        status="deleted",
        title=title
    )
```

---

**Tool 5: update_task**

**Input Schema**:
```python
class UpdateTaskInput(BaseModel):
    user_id: str
    task_id: int
    title: Optional[str] = None
    description: Optional[str] = None
    priority: Optional[Literal["HIGH", "MEDIUM", "LOW"]] = None
    tags: Optional[List[str]] = None
    due_date: Optional[str] = None  # ISO 8601 or null to clear
```

**Output Schema**:
```python
class UpdateTaskOutput(BaseModel):
    task_id: int
    status: Literal["updated"]
    title: str
    changes: Dict[str, Any]  # What was changed
```

**Pseudocode**:
```python
async def update_task(input: UpdateTaskInput, db: Session) -> UpdateTaskOutput:
    task = db.query(Task).filter(
        Task.id == input.task_id,
        Task.user_id == input.user_id
    ).first()

    if not task:
        raise TaskNotFoundError(input.task_id)

    changes = {}
    if input.title is not None:
        task.title = input.title
        changes["title"] = input.title
    if input.description is not None:
        task.description = input.description
        changes["description"] = input.description
    if input.priority is not None:
        task.priority = input.priority
        changes["priority"] = input.priority
    if input.tags is not None:
        task.tags = input.tags
        changes["tags"] = input.tags
    if input.due_date is not None:
        task.due_date = parse_iso8601(input.due_date) if input.due_date else None
        changes["due_date"] = input.due_date

    task.updated_at = datetime.utcnow()
    db.commit()

    return UpdateTaskOutput(
        task_id=task.id,
        status="updated",
        title=task.title,
        changes=changes
    )
```

---

### Component Breakdown

#### Component 1: ChatKit Frontend

**File**: `frontend-chatbot/src/components/ChatInterface.tsx`

**Responsibilities**:
- Render chat messages (user + assistant)
- Capture user input
- Send HTTP POST to `/api/chat/{user_id}`
- Handle loading states
- Display errors

**Dependencies**: OpenAI ChatKit library (or alternative React chat UI)

**Pseudocode**:
```typescript
async function sendMessage(message: string) {
  const response = await fetch(`/api/chat/${userId}`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${jwtToken}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      conversation_id: conversationId,
      message: message
    })
  });

  if (!response.ok) {
    if (response.status === 401) {
      // Redirect to login
      window.location.href = '/login';
    } else if (response.status === 503) {
      // Show "Service temporarily unavailable" message
      showError('Chat service is temporarily unavailable. Please try the web interface.');
    }
    return;
  }

  const data = await response.json();
  setConversationId(data.conversation_id);
  appendMessage({ role: 'assistant', content: data.response });
}
```

---

#### Component 2: FastAPI Chat Endpoint

**File**: `backend/src/api/chat.py`

**Responsibilities**:
- Validate JWT token
- Load/create conversation
- Append user message to DB
- Load conversation history
- Invoke OpenAI Agent
- Store agent response to DB
- Return response

**Dependencies**: FastAPI, SQLModel, OpenAI Agents SDK, MCP Server

**Pseudocode**:
```python
from fastapi import APIRouter, Depends, HTTPException
from sqlmodel import Session
from backend.src.api.auth import get_current_user
from backend.src.database import get_db
from backend.mcp.utils.conversation_manager import ConversationManager
from backend.mcp.utils.agent_client import AgentClient

router = APIRouter()

@router.post("/chat/{user_id}")
async def chat(
    user_id: str,
    request: ChatRequest,
    current_user: str = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # Security: Verify token user_id matches URL user_id
    if current_user != user_id:
        raise HTTPException(403, "Cannot access other user's conversations")

    # Load or create conversation
    conversation_id = request.conversation_id
    if not conversation_id:
        conversation = Conversation(user_id=user_id)
        db.add(conversation)
        db.commit()
        conversation_id = conversation.id
    else:
        # Verify conversation belongs to user
        conversation = db.query(Conversation).filter(
            Conversation.id == conversation_id,
            Conversation.user_id == user_id
        ).first()
        if not conversation:
            raise HTTPException(404, "Conversation not found")

    # Append user message
    user_message = Message(
        conversation_id=conversation_id,
        user_id=user_id,
        role="user",
        content=request.message,
        created_at=datetime.utcnow()
    )
    db.add(user_message)
    db.commit()

    # Load conversation history (last 50 messages, truncated to 8,000 tokens)
    history = await ConversationManager.load_conversation_history(
        db, conversation_id, user_id
    )

    # Invoke OpenAI Agent
    agent_client = AgentClient()
    agent_response = await agent_client.chat(
        conversation_history=history,
        new_message=request.message,
        user_id=user_id
    )

    # Store agent response
    assistant_message = Message(
        conversation_id=conversation_id,
        user_id=user_id,
        role="assistant",
        content=agent_response.content,
        created_at=datetime.utcnow()
    )
    db.add(assistant_message)
    db.commit()

    return {
        "conversation_id": conversation_id,
        "message_id": assistant_message.id,
        "response": agent_response.content,
        "tool_calls": agent_response.tool_calls  # Metadata for debugging
    }
```

---

#### Component 3: OpenAI Agent Client

**File**: `backend/mcp/utils/agent_client.py`

**Responsibilities**:
- Initialize OpenAI Agents SDK client
- Register 5 MCP tools
- Send conversation history + new message to agent
- Parse agent response (text + tool calls)
- Execute MCP tool calls
- Return final agent response

**Dependencies**: OpenAI Agents SDK, MCP Server tools

**Pseudocode**:
```python
from openai import OpenAI
from backend.mcp.tools import add_task, list_tasks, complete_task, delete_task, update_task

class AgentClient:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        # Register MCP tools with agent
        self.tools = [
            {
                "type": "function",
                "function": {
                    "name": "add_task",
                    "description": "Create a new task",
                    "parameters": AddTaskInput.schema()
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "list_tasks",
                    "description": "List tasks with optional filters",
                    "parameters": ListTasksInput.schema()
                }
            },
            # ... complete_task, delete_task, update_task
        ]

    async def chat(
        self,
        conversation_history: List[Dict],
        new_message: str,
        user_id: str
    ) -> AgentResponse:
        # Build messages for agent
        messages = conversation_history + [
            {"role": "user", "content": new_message}
        ]

        # Call OpenAI Agents API with tools
        response = await self.client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages,
            tools=self.tools,
            tool_choice="auto"
        )

        # Parse response
        assistant_message = response.choices[0].message

        # If agent wants to call tools
        tool_calls = []
        if assistant_message.tool_calls:
            for tool_call in assistant_message.tool_calls:
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)

                # Execute MCP tool
                tool_result = await self._execute_tool(
                    tool_name, tool_args, user_id
                )
                tool_calls.append({
                    "tool": tool_name,
                    "parameters": tool_args,
                    "result": tool_result
                })

        return AgentResponse(
            content=assistant_message.content or "Done!",
            tool_calls=tool_calls
        )

    async def _execute_tool(self, tool_name: str, args: dict, user_id: str):
        """Execute MCP tool and return result"""
        args["user_id"] = user_id  # Inject user_id for security

        if tool_name == "add_task":
            return await add_task(AddTaskInput(**args), db)
        elif tool_name == "list_tasks":
            return await list_tasks(ListTasksInput(**args), db)
        # ... etc
```

---

#### Component 4: Conversation History Manager

**File**: `backend/mcp/utils/conversation_manager.py`

**Responsibilities**:
- Load last 50 messages from database
- Calculate total token count (estimate: chars / 4)
- Truncate if > 8,000 tokens
- Keep last 10 messages intact
- Summarize older messages

**Dependencies**: SQLModel, tiktoken (optional for accurate counting)

**Pseudocode** (from constitution):
```python
class ConversationManager:
    MAX_CONTEXT_TOKENS = 8000
    CHARS_PER_TOKEN = 4
    MAX_CONTEXT_CHARS = 8000 * 4  # 32,000
    MAX_MESSAGES = 50
    RECENT_MESSAGES_ALWAYS_INCLUDE = 10

    @staticmethod
    async def load_conversation_history(
        db: Session,
        conversation_id: int,
        user_id: str
    ) -> List[Dict[str, str]]:
        messages = db.exec(
            select(Message)
            .where(
                Message.conversation_id == conversation_id,
                Message.user_id == user_id
            )
            .order_by(Message.created_at.asc())
            .limit(ConversationManager.MAX_MESSAGES)
        ).all()

        if not messages:
            return []

        history = [
            {"role": msg.role, "content": msg.content}
            for msg in messages
        ]

        total_chars = sum(len(msg["content"]) for msg in history)

        if total_chars <= ConversationManager.MAX_CONTEXT_CHARS:
            return history

        return ConversationManager._compress_history(history)

    @staticmethod
    def _compress_history(history: List[Dict]) -> List[Dict]:
        if len(history) <= ConversationManager.RECENT_MESSAGES_ALWAYS_INCLUDE:
            return history

        old_messages = history[:-ConversationManager.RECENT_MESSAGES_ALWAYS_INCLUDE]
        recent_messages = history[-ConversationManager.RECENT_MESSAGES_ALWAYS_INCLUDE:]

        # Summarize old messages
        task_actions = []
        for msg in old_messages:
            content_lower = msg["content"].lower()
            if "added" in content_lower or "created" in content_lower:
                task_actions.append("created tasks")
            elif "completed" in content_lower or "done" in content_lower:
                task_actions.append("completed tasks")
            elif "deleted" in content_lower or "removed" in content_lower:
                task_actions.append("deleted tasks")

        action_summary = ", ".join(set(task_actions)) if task_actions else "managed tasks"
        summary = {
            "role": "system",
            "content": f"[Earlier: User {action_summary}. {len(old_messages)} messages summarized.]"
        }

        return [summary] + recent_messages
```

---

#### Component 5: Circuit Breaker (Resilience)

**File**: `backend/mcp/utils/circuit_breaker.py`

**Responsibilities**:
- Track OpenAI API failures
- Open circuit after 5 consecutive failures
- Reject requests fast when circuit open (503 error)
- Attempt recovery after 60 seconds

**Dependencies**: None (pure Python)

**Pseudocode** (from constitution Section XVI):
```python
from enum import Enum
from datetime import datetime, timedelta

class CircuitState(Enum):
    CLOSED = "closed"      # Normal
    OPEN = "open"          # Failing
    HALF_OPEN = "half_open"  # Testing recovery

class CircuitBreaker:
    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
        timeout_seconds: int = 30
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.timeout = timeout_seconds

        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED

    async def call(self, func, *args, **kwargs):
        if self.state == CircuitState.OPEN:
            if self._should_attempt_recovery():
                self.state = CircuitState.HALF_OPEN
            else:
                raise CircuitBreakerOpenError("Circuit breaker OPEN - OpenAI API unavailable")

        try:
            result = await asyncio.wait_for(
                func(*args, **kwargs),
                timeout=self.timeout
            )

            if self.state == CircuitState.HALF_OPEN:
                self._record_success()

            return result

        except Exception as e:
            self._record_failure()
            raise

    def _record_failure(self):
        self.failure_count += 1
        self.last_failure_time = datetime.utcnow()

        if self.failure_count >= self.failure_threshold:
            self.state = CircuitState.OPEN
            logger.error(f"Circuit breaker OPEN - {self.failure_count} failures")

    def _record_success(self):
        self.failure_count = 0
        self.state = CircuitState.CLOSED
        logger.info("Circuit breaker CLOSED - recovery successful")

    def _should_attempt_recovery(self) -> bool:
        if not self.last_failure_time:
            return True

        time_since_failure = datetime.utcnow() - self.last_failure_time
        return time_since_failure.total_seconds() > self.recovery_timeout
```

---

### Quickstart Guide

**File**: `specs/002-ai-chatbot-mcp/quickstart.md`

**Local Development Setup**:

```bash
# 1. Backend Setup
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install fastapi sqlmodel uvicorn openai python-jose[cryptography] pytest httpx

# Set environment variables
export DATABASE_URL="<Neon PostgreSQL connection string>"
export OPENAI_API_KEY="<your-openai-api-key>"
export AUTH_SECRET="<better-auth-secret-from-phase-2>"
export PORT=8000
export ENVIRONMENT="development"

# Run database migrations (create conversations, messages tables)
python -m alembic upgrade head

# Start FastAPI server
uvicorn src.api.main:app --reload --port 8000

# 2. Frontend Setup (separate terminal)
cd frontend-chatbot
npm install

# Set environment variables
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > .env.local

npm run dev  # Starts on http://localhost:3001

# 3. Test the integration
# Open http://localhost:3001
# Login with Phase 2 credentials
# Send message: "Add a task to test the chatbot"
# Verify task appears in Phase 2 web UI (http://localhost:3000)
```

---

## Architecture Decisions (ADRs)

### ADR 001: Stateless Architecture with Database-Backed Conversations

**Status**: Approved

**Context**: We need to decide how to store conversation state. Options:
1. In-memory (server RAM)
2. Database-backed (PostgreSQL)
3. External cache (Redis)

**Decision**: Use database-backed conversations (Option 2)

**Rationale**:
- **Horizontal Scalability**: Load balancer can route request N to server A, request N+1 to server B without session affinity
- **Fault Tolerance**: Server crash = zero data loss
- **Simplicity**: No cache invalidation complexity, no Redis dependency
- **Phase 4 Ready**: Kubernetes can scale pods without state management
- **Constitution Compliance**: Principle II (Radical Statelessness) REQUIRES database-only state

**Consequences**:
- Every request queries database (acceptable: < 100ms latency for 50 messages)
- No session affinity needed (simplifies load balancer config)
- Database becomes critical dependency (mitigated: Neon has 99.95% SLA)

**Alternatives Rejected**:
- Option 1 (In-memory): Violates constitution, prevents horizontal scaling
- Option 3 (Redis): Adds complexity without significant benefit (PostgreSQL is fast enough)

---

### ADR 002: Conversation History Truncation Strategy

**Status**: Approved

**Context**: GPT-4 has token limits. Long conversations will exceed limits and crash. We need a truncation strategy.

**Decision**: Load last 50 messages, keep last 10 intact, summarize older messages if > 8,000 tokens

**Rationale**:
- **Token Budget**: 8,000 tokens ≈ 32,000 chars (4 chars/token estimate)
- **Recent Context Critical**: Last 10 messages needed for pronoun resolution ("mark the first one as done")
- **Performance**: LIMIT 50 prevents unbounded queries
- **User Experience**: Most conversations < 50 messages (no truncation needed)

**Strategy**:
1. Query: `SELECT * FROM messages WHERE conversation_id = ? ORDER BY created_at ASC LIMIT 50`
2. Calculate total characters
3. If < 32,000 chars, return full history
4. If > 32,000 chars, compress:
   - Keep last 10 messages intact
   - Summarize older messages: `[Earlier: User created tasks, completed tasks. 40 messages summarized.]`

**Consequences**:
- Very long conversations (> 50 messages) lose oldest context
- Users may need to start new conversation after extended use
- Trade-off: Simplicity vs. perfect context retention (we choose simplicity)

**Alternatives Rejected**:
- Sliding window only (no summary): Loss of all context beyond 10 messages
- Semantic summarization (GPT-based): Too slow, too expensive
- Unlimited history: Will crash on token limit

---

### ADR 003: Single Endpoint Pattern (POST /api/chat Only)

**Status**: Approved

**Context**: Traditional REST APIs have multiple endpoints (GET /tasks, POST /tasks, etc.). AI-powered apps can use natural language for routing.

**Decision**: Single endpoint `POST /api/chat/{user_id}` for all task operations

**Rationale**:
- **Natural Language Routing**: User says "show my tasks" → Agent calls list_tasks tool
- **Simplified Client**: Frontend only needs one API call
- **Agent-First Design**: Agent determines intent, not URL paths
- **Constitution Compliance**: Section VII (Single Endpoint Doctrine) REQUIRES this pattern

**Behavior**:
- POST /api/chat: Accepts text message, returns text response
- Agent interprets intent and calls appropriate MCP tools
- No REST endpoints like GET /tasks, POST /tasks, etc.

**Consequences**:
- All operations funnel through natural language (can't bypass with direct REST calls)
- Debugging requires conversation logs (can't use Postman for quick tests)
- Frontend simpler (one API call vs. many)

**Alternatives Rejected**:
- Traditional REST API: Requires dual interface (REST + chat), more complexity
- GraphQL: Doesn't align with natural language paradigm

---

### ADR 004: MCP Tools as Atomic, Stateless Functions

**Status**: Approved

**Context**: MCP tools need to be reliable, testable, and scalable. We need to decide their architecture.

**Decision**: Each MCP tool is a pure function: Input → Database Query → Output (no side effects, no state)

**Rationale**:
- **Testability**: Easy to unit test with mock database
- **Reliability**: No hidden dependencies, deterministic behavior
- **Scalability**: Stateless tools can run on any server instance
- **Constitution Compliance**: Principle II + III require stateless, database-backed tools

**Contract**:
```python
async def add_task(input: AddTaskInput, db: Session) -> AddTaskOutput:
    # 1. Validate input (Pydantic handles this)
    # 2. Query database
    # 3. Return result
    # NO: Global state, in-memory caching, file I/O
```

**Consequences**:
- Every tool call hits database (acceptable: PostgreSQL is fast)
- Tools are independently deployable (microservices-ready)
- Tools can't share state (must use database to communicate)

**Alternatives Rejected**:
- Stateful tools with caching: Violates constitution, prevents scaling
- Tools calling other tools: Creates tight coupling, harder to test

---

## Testing Strategy

### Test Pyramid

**Total Tests**: 70+ (50 unit + 15 integration + 5 E2E)
**Target Coverage**: ≥85%

```
        ┌─────────────┐
        │  E2E Tests  │  ← 5 tests: Full conversation flows
        │     (5)     │     - Create → List → Complete → Delete
        └─────────────┘     - Context retention across messages
       ┌───────────────┐     - Error recovery flows
       │ Integration   │  ← 15 tests: API + Agent + MCP + DB
       │     (15)      │     - Chat endpoint with mock agent
       └───────────────┘     - Agent with mock MCP
      ┌─────────────────┐     - MCP with test database
      │  Unit Tests     │  ← 50 tests: Individual functions
      │      (50)       │     - Each MCP tool (5 × 6 tests = 30)
      └─────────────────┘     - Models (10 tests)
                              - Conversation manager (10 tests)
```

### Unit Tests (50+)

**File**: `backend/tests/unit/test_mcp_tools.py`

**Coverage**:
- `add_task`: 6 tests
  - ✅ Success: Create task with all fields
  - ✅ Success: Create task with minimal fields (title only)
  - ✅ Error: Empty title
  - ✅ Error: Invalid priority
  - ✅ Error: Invalid due_date format
  - ✅ Security: User isolation (can't create task for other user)

- `list_tasks`: 8 tests
  - ✅ Success: List all tasks
  - ✅ Success: Filter by status (pending)
  - ✅ Success: Filter by status (completed)
  - ✅ Success: Filter by priority
  - ✅ Success: Filter by tag
  - ✅ Success: Empty list (no tasks)
  - ✅ Success: Pagination (50+ tasks)
  - ✅ Security: User isolation (can't see other user's tasks)

- `complete_task`: 6 tests
  - ✅ Success: Mark incomplete task as complete
  - ✅ Success: Mark already complete task (idempotent)
  - ✅ Error: Task not found
  - ✅ Error: Task belongs to different user
  - ✅ Success: Updates updated_at timestamp
  - ✅ Success: Recurring task creates new instance (if implemented)

- `delete_task`: 5 tests
  - ✅ Success: Delete existing task
  - ✅ Error: Task not found
  - ✅ Error: Task belongs to different user
  - ✅ Success: Returns deleted task title
  - ✅ Success: Task no longer queryable after deletion

- `update_task`: 5 tests
  - ✅ Success: Update title
  - ✅ Success: Update multiple fields
  - ✅ Error: Task not found
  - ✅ Error: No fields provided
  - ✅ Security: User isolation

**File**: `backend/tests/unit/test_models.py`

- `Conversation` model: 3 tests
  - ✅ Create conversation with default timestamps
  - ✅ Cascade delete messages when conversation deleted
  - ✅ Index on user_id works

- `Message` model: 3 tests
  - ✅ Create message with valid role ("user")
  - ✅ Create message with valid role ("assistant")
  - ✅ Error: Invalid role (neither "user" nor "assistant")

**File**: `backend/tests/unit/test_conversation_manager.py`

- `load_conversation_history`: 4 tests
  - ✅ Success: Load history under token limit
  - ✅ Success: Truncate history over token limit
  - ✅ Success: Keep last 10 messages intact
  - ✅ Success: Summarize older messages

- `_compress_history`: 3 tests
  - ✅ Summary includes task actions
  - ✅ Summary respects 10-message minimum
  - ✅ Summary reduces total characters

---

### Integration Tests (15+)

**File**: `backend/tests/integration/test_chat_endpoint.py`

- Chat endpoint: 8 tests
  - ✅ Success: New conversation created on first message
  - ✅ Success: Existing conversation continued
  - ✅ Success: User message stored to database
  - ✅ Success: Assistant response stored to database
  - ✅ Error: Invalid JWT token (401)
  - ✅ Error: Token user_id mismatch (403)
  - ✅ Error: Conversation not found (404)
  - ✅ Error: Invalid message format (422)

**File**: `backend/tests/integration/test_agent_orchestration.py`

- Agent orchestration: 7 tests
  - ✅ Success: Agent calls add_task tool
  - ✅ Success: Agent calls list_tasks tool
  - ✅ Success: Agent calls multiple tools in sequence
  - ✅ Success: Agent uses conversation context (pronouns)
  - ✅ Error: OpenAI API timeout
  - ✅ Error: Circuit breaker opens after failures
  - ✅ Error: Invalid tool parameters

---

### E2E Tests (5+)

**File**: `backend/tests/e2e/test_conversation_flows.py`

- Complete conversation flows: 5 tests
  - ✅ Flow 1: Create → List → Complete → Delete
    - User: "Add a task to buy milk"
    - User: "Show my tasks"
    - User: "Mark buy milk as done"
    - User: "Delete the milk task"
    - Assert: All operations succeed, database state correct

  - ✅ Flow 2: Context retention across messages
    - User: "Show my tasks"
    - Assistant: "You have 3 tasks: 1) Buy milk, 2) Call mom, 3) Pay bills"
    - User: "Complete the first one"
    - Assert: Agent correctly identifies "first one" = "Buy milk"

  - ✅ Flow 3: Error recovery (task not found)
    - User: "Delete task about XYZ"
    - Assistant: "I couldn't find a task about XYZ. Would you like to see all your tasks?"
    - Assert: Graceful error handling, no crash

  - ✅ Flow 4: Multi-tool workflow (list then complete)
    - User: "Show high priority tasks and mark the first one as done"
    - Assert: Agent calls list_tasks(priority="HIGH"), then complete_task(task_id)

  - ✅ Flow 5: Conversation history persistence (server restart simulation)
    - User sends 5 messages
    - Simulate server restart (clear in-memory state)
    - User sends 6th message
    - Assert: Agent still has context from messages 1-5

---

## Deployment Checklist

### Development Environment

- [x] Python 3.11+ installed
- [x] Neon PostgreSQL database accessible
- [x] OpenAI API key obtained
- [x] Better Auth configured (from Phase 2)
- [ ] Database migrations run (`alembic upgrade head`)
- [ ] FastAPI server starts without errors
- [ ] Health checks pass (`/health`, `/ready`)
- [ ] Frontend can connect to backend
- [ ] Can send test message end-to-end

### Cloud-Native Requirements (Phase 4 Readiness)

- [ ] All configuration in environment variables (`.env.example` provided)
- [ ] Health check endpoints implemented:
  - [ ] GET /health (liveness) - returns 200 in < 500ms
  - [ ] GET /ready (readiness) - checks database + OpenAI connectivity
- [ ] Graceful shutdown handlers:
  - [ ] SIGTERM handler registered
  - [ ] Active requests tracked
  - [ ] Database connections closed on shutdown
- [ ] Port binding:
  - [ ] Server binds to 0.0.0.0 (not 127.0.0.1)
  - [ ] PORT environment variable respected
- [ ] Structured JSON logging:
  - [ ] All logs to stdout (not files)
  - [ ] PII protection (user_id hashed, no task content in logs)
  - [ ] Log levels: DEBUG (dev), INFO (prod), ERROR (always)
- [ ] Conversation history management:
  - [ ] MAX_MESSAGES = 50 enforced
  - [ ] Token limit check (8,000 tokens)
  - [ ] Truncation/summarization implemented
- [ ] Circuit breaker:
  - [ ] Failure threshold = 5
  - [ ] Recovery timeout = 60s
  - [ ] Request timeout = 30s

### Testing

- [ ] Unit tests pass (50+)
- [ ] Integration tests pass (15+)
- [ ] E2E tests pass (5+)
- [ ] Test coverage ≥ 85%
- [ ] Security tests pass:
  - [ ] No cross-user data access
  - [ ] JWT validation on all requests
  - [ ] Input sanitization prevents injection

### Phase 2 Integration

- [ ] Tasks created via chatbot appear in web UI (< 1 second)
- [ ] Tasks created via web UI accessible to chatbot
- [ ] Same JWT token works for both UIs
- [ ] Database schema compatible (no breaking changes)

### Production Deployment

- [ ] Backend deployed to production server
- [ ] Frontend deployed (Vercel/Netlify)
- [ ] Environment variables configured (no secrets in code)
- [ ] OpenAI ChatKit domain allowlisted (if using ChatKit)
- [ ] Health checks monitored
- [ ] Logs aggregated (Kubernetes logs or CloudWatch)
- [ ] Metrics dashboard (request count, latency, error rate)
- [ ] Alerts configured (error rate > 5%, latency > 5s)

---

## Risk Analysis

### Risk 1: OpenAI API Cost Overruns
- **Impact**: High usage exceeds budget
- **Likelihood**: Medium (depends on adoption)
- **Mitigation**: Rate limiting (10 req/min/user), daily spend monitoring, spending alerts
- **Contingency**: Reduce rate limit, add usage warnings

### Risk 2: OpenAI API Downtime
- **Impact**: Chat unavailable, poor UX
- **Likelihood**: Low (99.9% SLA)
- **Mitigation**: Circuit breaker, fallback message, direct users to Phase 2 web UI
- **Contingency**: Manual announcement, status page

### Risk 3: Token Limit Exceeded (Long Conversations)
- **Impact**: Degraded context, user confusion
- **Likelihood**: Medium (power users may chat extensively)
- **Mitigation**: Truncation strategy (last 10 messages + summary), warn at 40 messages
- **Contingency**: Suggest starting new conversation

### Risk 4: MCP SDK Not Available/Immature
- **Impact**: Development delays, custom implementation needed
- **Likelihood**: Medium (new tech)
- **Mitigation**: Prototype early, have fallback (direct tool calling without MCP wrapper)
- **Contingency**: Allocate 1 week buffer for custom MCP implementation

### Risk 5: Natural Language Ambiguity
- **Impact**: Misinterpretation, wrong operations
- **Likelihood**: Medium (NL inherently ambiguous)
- **Mitigation**: Confirmation for destructive ops (delete), clarifying questions, allow "undo"
- **Contingency**: User feedback loop, improve prompts

### Risk 6: Database Performance Degradation
- **Impact**: Slow responses, timeouts
- **Likelihood**: Low (Neon scales well)
- **Mitigation**: Index conversations/messages tables, connection pooling, query monitoring
- **Contingency**: Add Redis cache layer if needed

### Risk 7: Security Vulnerabilities (Injection, XSS)
- **Impact**: Data breach, unauthorized access
- **Likelihood**: Low (with proper validation)
- **Mitigation**: Pydantic validation, sanitize AI responses, parameterized queries, security audit
- **Contingency**: Emergency patch, incident response plan

### Risk 8: Phase 2 Dependency Issues
- **Impact**: Cannot integrate with web app
- **Likelihood**: Low (Phase 2 complete)
- **Mitigation**: Validate Phase 2 schema before starting, integration tests
- **Contingency**: Coordinate with Phase 2 team on schema changes

---

## Next Steps (After Plan Approval)

1. **Create Prompt History Record (PHR)** for this planning phase
2. **Execute `/sp.tasks`** to break plan into atomic, testable tasks
3. **Begin implementation** following TDD workflow:
   - RED: Write failing test
   - GREEN: Implement minimal code to pass
   - REFACTOR: Clean up code
   - DOCUMENT: Create PHR for iteration
4. **Phase 0 First**: Complete research.md before coding
5. **Phase 1 Next**: Generate data-model.md, contracts/, quickstart.md

**Estimated Timeline** (No time estimates per policy, but dependency order):
- Phase 0: Research (depends on: none)
- Phase 1: Design (depends on: Phase 0 complete)
- Phase 2: Task breakdown (depends on: Phase 1 complete)
- Phase 3: Implementation (depends on: Phase 2 complete)
- Phase 4: Testing (depends on: Phase 3 complete)
- Phase 5: Deployment (depends on: Phase 4 passing)

**Ready for `/sp.tasks` command.** ✅

---

## Appendix: Key References

- **Constitution**: `.specify/memory/phase-3-constitution.md` (v1.1.0)
- **Spec**: `specs/002-ai-chatbot-mcp/spec.md`
- **Phase 2 Models**: `backend/src/models/task.py`, `backend/src/models/user.py`
- **Phase 2 Auth**: `backend/src/api/auth.py`
- **OpenAI Agents SDK**: https://platform.openai.com/docs/agents (research pending)
- **MCP Protocol**: https://spec.mcp.dev/ (research pending)

---

**Plan Status**: ✅ COMPLETE - Ready for task breakdown (`/sp.tasks`)
**Plan Version**: 1.0
**Created**: 2025-12-25
**Last Updated**: 2025-12-25
